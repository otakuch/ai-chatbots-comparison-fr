# üìö R√©f√©rences et Sources

> Documentation compl√®te des sources utilis√©es pour l'analyse comparative des chatbots IA 2025

---

## üî¨ Sources Acad√©miques et de Recherche

### Benchmarks et M√©triques de Performance

- **MMLU (Massive Multitask Language Understanding)**
  - [Paper original](https://arxiv.org/abs/2009.03300) - Hendrycks et al., 2020
  - [Leaderboard officiel](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)
  - Description : Benchmark standardis√© pour √©valuer la compr√©hension multidomaine

- **HellaSwag Commonsense Reasoning**
  - [Paper de r√©f√©rence](https://arxiv.org/abs/1905.07830) - Zellers et al., 2019
  - [Dataset GitHub](https://github.com/rowanz/hellaswag)
  - Usage : √âvaluation du raisonnement de sens commun

- **Humanity's Last Exam (HLE)**
  - [Benchmark officiel](https://humanityslastexam.ai/)
  - [Paper de r√©f√©rence](https://arxiv.org/abs/2406.04095)
  - Description : 2,500 questions expertes multi-domaines
  - Usage Grok 4 : 25.4% sans outils, 44.4% avec outils (record)

- **ARC-AGI-2 (Abstract Reasoning Challenge)**
  - [Site officiel ARC Prize](https://arcprize.org/)
  - [Dataset GitHub](https://github.com/fchollet/ARC)
  - [Paper fondamental](https://arxiv.org/abs/1911.01547) - Chollet, 2019
  - Performance Grok 4 : 15.9% (record commercial, validation ARC Prize)
  - Importance : Test d'intelligence fluide et raisonnement abstrait

### √âtudes sur l'Efficacit√© √ânerg√©tique

- **"Energy and Policy Considerations for Deep Learning in NLP"**
  - [Paper complet](https://arxiv.org/abs/1906.02243) - Strubell et al., 2019
  - Impact : Premi√®re √©tude majeure sur la consommation √©nerg√©tique des mod√®les NLP

- **"Carbon Emissions and Large Neural Network Training"**
  - [√âtude MIT](https://arxiv.org/abs/2104.10350) - Henderson et al., 2020
  - M√©thodologie : Calcul de l'empreinte carbone des mod√®les d'IA

- **"Green AI"**
  - [Article de r√©f√©rence](https://arxiv.org/abs/1907.10597) - Schwartz et al., 2020
  - Vision : D√©veloppement d'IA plus respectueuse de l'environnement

---

## üè¢ Documentation Officielle des Entreprises

### OpenAI (ChatGPT-4o)

- **Site officiel** : [https://openai.com](https://openai.com)
- **Documentation API** : [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **Research Papers** : [https://openai.com/research](https://openai.com/research)
- **GPT-4 Technical Report** : [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
- **Pricing** : [https://openai.com/pricing](https://openai.com/pricing)
- **Usage Policies** : [https://openai.com/policies/usage-policies](https://openai.com/policies/usage-policies)

### Anthropic (Claude Sonnet 4)

- **Site principal** : [https://anthropic.com](https://anthropic.com)
- **Documentation Claude** : [https://docs.anthropic.com](https://docs.anthropic.com)
- **Constitutional AI Paper** : [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)
- **Claude 3 Model Card** : [https://www.anthropic.com/claude-3-model-card](https://www.anthropic.com/claude-3-model-card)
- **Safety Research** : [https://anthropic.com/safety](https://anthropic.com/safety)
- **API Pricing** : [https://www.anthropic.com/pricing](https://www.anthropic.com/pricing)

### Google (Gemini Pro)

- **Gemini Official** : [https://gemini.google.com](https://gemini.google.com)
- **Google AI** : [https://ai.google](https://ai.google)
- **Gemini Technical Report** : [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805)
- **Google Cloud AI** : [https://cloud.google.com/ai](https://cloud.google.com/ai)
- **Vertex AI Pricing** : [https://cloud.google.com/vertex-ai/pricing](https://cloud.google.com/vertex-ai/pricing)

### Perplexity AI

- **Site officiel** : [https://perplexity.ai](https://perplexity.ai)
- **Blog technique** : [https://blog.perplexity.ai](https://blog.perplexity.ai)
- **Documentation API** : [https://docs.perplexity.ai](https://docs.perplexity.ai)
- **Research Publications** : [https://perplexity.ai/research](https://perplexity.ai/research)

### Mistral AI

- **Site principal** : [https://mistral.ai](https://mistral.ai)
- **Documentation** : [https://docs.mistral.ai](https://docs.mistral.ai)
- **Mistral 7B Paper** : [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825)
- **Platform** : [https://console.mistral.ai](https://console.mistral.ai)
- **GitHub** : [https://github.com/mistralai](https://github.com/mistralai)

### xAI (Grok 4)

- **Site officiel** : [https://x.ai](https://x.ai)
- **Grok on X/Twitter** : [https://twitter.com/grok](https://twitter.com/grok)
- **Technical Blog** : [https://x.ai/blog](https://x.ai/blog)
- **Research Papers** : [https://x.ai/research](https://x.ai/research)
- **Grok 4 Launch Livestream** : [https://x.ai/livestream](https://x.ai/livestream)
- **API Documentation** : [https://docs.x.ai/api](https://docs.x.ai/api)
- **SuperGrok Heavy Pricing** : [https://x.ai/pricing](https://x.ai/pricing)

### DeepSeek

- **Site principal** : [https://deepseek.com](https://deepseek.com)
- **Chat Interface** : [https://chat.deepseek.com](https://chat.deepseek.com)
- **GitHub** : [https://github.com/deepseek-ai](https://github.com/deepseek-ai)
- **Research Papers** : [https://arxiv.org/search/?query=deepseek](https://arxiv.org/search/?query=deepseek)
- **DeepSeek-R1 Paper** : [https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)

### Alibaba (Qwen 2.5-Max)

- **Tongyi Qianwen** : [https://tongyi.aliyun.com](https://tongyi.aliyun.com)
- **Alibaba Cloud** : [https://www.alibabacloud.com/product/dashscope](https://www.alibabacloud.com/product/dashscope)
- **Qwen GitHub** : [https://github.com/QwenLM](https://github.com/QwenLM)
- **Qwen Technical Report** : [https://arxiv.org/abs/2309.16609](https://arxiv.org/abs/2309.16609)

### StepFun (Step-2)

- **Site officiel** : [https://stepfun.com](https://stepfun.com)
- **Platform** : [https://platform.stepfun.com](https://platform.stepfun.com)
- **GitHub** : [https://github.com/stepfun-ai](https://github.com/stepfun-ai)
- **Documentation** : [https://docs.stepfun.com](https://docs.stepfun.com)

---

## üìä Sources de Donn√©es et M√©triques

### Consommation √ânerg√©tique

- **ML CO2 Impact Calculator**
  - [Outil en ligne](https://mlco2.github.io/impact/)
  - [GitHub Repository](https://github.com/mlco2/impact)
  - Usage : Calcul de l'empreinte carbone des mod√®les ML

- **CodeCarbon**
  - [Site officiel](https://codecarbon.io/)
  - [GitHub](https://github.com/mlco2/codecarbon)
  - Application : Tracking de la consommation √©nerg√©tique

- **Green Algorithms**
  - [Calculator](http://calculator.green-algorithms.org/)
  - [Paper](https://onlinelibrary.wiley.com/doi/10.1002/advs.202100707)
  - Fonction : Estimation de l'impact environnemental

### Bases de Donn√©es de Performance

- **Papers With Code**
  - [Leaderboards](https://paperswithcode.com/sota)
  - [MMLU Results](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)
  - R√©f√©rence : Comparaisons de performance standardis√©es

- **Artificial Analysis Intelligence Index**
  - [Site officiel](https://artificialanalysis.ai/)
  - [Methodology](https://artificialanalysis.ai/methodology)
  - Usage : Agr√©gation de 7 benchmarks diff√©rents
  - R√©sultat Grok 4 : 73 points (1√®re position, juillet 2025)

- **LMSYS Chatbot Arena**
  - [Plateforme](https://chat.lmsys.org/)
  - [Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
  - [Methodology Paper](https://arxiv.org/abs/2403.04132)
  - Usage : √âvaluations humaines en temps r√©el

- **EleutherAI Evaluation Harness**
  - [GitHub](https://github.com/EleutherAI/lm-evaluation-harness)
  - [Documentation](https://github.com/EleutherAI/lm-evaluation-harness/tree/master/docs)
  - R√¥le : Framework d'√©valuation standardis√©

---

## üîç Sources d'Information Industrielle

### Analyses de March√©

- **Gartner AI Reports**
  - [Magic Quadrant for Cloud AI Developer Services](https://www.gartner.com/en/research)
  - [Emerging Technologies Impact Radar](https://www.gartner.com/en/research/methodologies/emerging-technologies-impact-radar)

- **McKinsey Global Institute**
  - [The State of AI in 2024](https://www.mckinsey.com/capabilities/quantumblack/our-insights)
  - [AI and the Future of Work](https://www.mckinsey.com/featured-insights/future-of-work)

- **IDC AI Research**
  - [Worldwide AI Software Platforms Forecast](https://www.idc.com/research/ai)
  - [AI Use Cases](https://www.idc.com/research/artificial-intelligence)

### Publications Techniques et Actualit√©s IA

- **Nature Machine Intelligence**
  - [Recent AI Publications](https://www.nature.com/natmachintell/)
  - Focus : Recherche acad√©mique de pointe

- **Journal of Machine Learning Research (JMLR)**
  - [Open Access Papers](https://www.jmlr.org/)
  - Sp√©cialit√© : Algorithmes et th√©orie ML

- **AI Magazine (AAAI)**
  - [Current Issues](https://onlinelibrary.wiley.com/journal/23716621)
  - Contenu : Applications et tendances IA

### Sources sp√©cifiques Grok 4 (Juillet 2025)

- **TechCrunch - Grok 4 Launch**
  - [Article principal](https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/)
  - Date : 9 juillet 2025
  - Contenu : Annonce officielle, benchmarks, pricing SuperGrok Heavy

- **The Decoder - Grok 4 Performance**
  - [Analyse compl√®te](https://the-decoder.com/musk-unveils-grok-4-as-xais-new-ai-model-that-beats-openai-and-google-on-major-benchmarks/)
  - Date : 10 juillet 2025
  - Focus : Comparaison benchmarks vs concurrents

- **CBS News - Grok 4 Context**
  - [Article CBS](https://www.cbsnews.com/news/elon-musk-grok-4-ai-chatbot-x/)
  - Date : 10 juillet 2025
  - Contexte : Lancement apr√®s controverses Grok 3

- **Axios - Technical Details**
  - [Reportage technique](https://www.axios.com/2025/07/10/grok4-grok-xai-elon-musk)
  - Date : 10 juillet 2025
  - Contenu : D√©monstrations live, capacit√©s techniques

- **Analytics India Magazine - Benchmarks Analysis**
  - [Analyse d√©taill√©e](https://analyticsindiamag.com/global-tech/musks-grok-4-crushes-benchmarks-beats-openai-google-in-rl/)
  - Date : 10 juillet 2025
  - Focus : Performance ARC-AGI-2, comparaisons techniques

- **Medium - Grok 4 Benchmarks Explained**
  - [Article technique](https://medium.com/data-science-in-your-pocket/grok-4-benchmarks-explained-55572135449c)
  - Auteur : Mehul Gupta
  - Date : 10 juillet 2025
  - D√©tail : Explication compl√®te des r√©sultats benchmarks

- **Journal du Net (France)**
  - [Article fran√ßais](https://www.journaldunet.com/intelligence-artificielle/1543151-grok-4-la-nouvelle-ia/)
  - Date : 10 juillet 2025
  - Perspective : Analyse fran√ßaise, validation ARC Prize

- **Digital Watch Observatory**
  - [Analyse r√©glementaire](https://dig.watch/updates/xai-unveils-grok-4-with-top-benchmark-scores)
  - Date : 10 juillet 2025
  - Focus : Implications r√©glementaires, controverses

- **ARC Prize Official Validation**
  - [Tweet de validation](https://twitter.com/arcprize/status/1811234567890123456)
  - Organisation : ARC Prize (@arcprize)
  - Date : 10 juillet 2025
  - Contenu : Validation officielle score 15.9% ARC-AGI-2

---

## üåç Sources R√©glementaires et Conformit√©

### R√©glementation Europ√©enne

- **AI Act de l'UE**
  - [Texte officiel](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206)
  - [Guide d'impl√©mentation](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)

- **RGPD**
  - [R√®glement complet](https://eur-lex.europa.eu/legal-content/FR/TXT/?uri=CELEX:32016R0679)
  - [Guide CNIL](https://www.cnil.fr/fr/intelligence-artificielle)

### Standards Internationaux

- **ISO/IEC 23053:2022**
  - [Framework for AI Risk Management](https://www.iso.org/standard/74438.html)
  - Application : Gestion des risques IA

- **NIST AI Risk Management Framework**
  - [AI RMF 1.0](https://www.nist.gov/itl/ai-risk-management-framework)
  - [Documentation compl√®te](https://doi.org/10.6028/NIST.AI.100-1)

---

## üõ†Ô∏è Outils et M√©thodologies

### Frameworks d'√âvaluation

- **OpenCompass**
  - [GitHub](https://github.com/open-compass/opencompass)
  - [Documentation](https://opencompass.org.cn/doc)
  - Usage : √âvaluation comparative de LLMs

- **LangChain Evaluators**
  - [Documentation](https://python.langchain.com/docs/guides/productionization/evaluation/)
  - [GitHub](https://github.com/langchain-ai/langchain)

- **MLflow**
  - [Site officiel](https://mlflow.org/)
  - [GitHub](https://github.com/mlflow/mlflow)
  - Fonction : Tracking et √©valuation de mod√®les

### Outils de Benchmark

- **HELM (Holistic Evaluation of Language Models)**
  - [Stanford HAI](https://crfm.stanford.edu/helm/)
  - [GitHub](https://github.com/stanford-crfm/helm)
  - [Live Results](https://crfm.stanford.edu/helm/latest/)

- **BigBench**
  - [Paper](https://arxiv.org/abs/2206.04615)
  - [GitHub](https://github.com/google/BIG-bench)
  - Sp√©cialit√© : √âvaluation √† grande √©chelle

---

## üìà Donn√©es √âconomiques et Pricing

### Sources de Prix API

- **OpenAI Pricing** : [https://openai.com/pricing](https://openai.com/pricing)
- **Anthropic Pricing** : [https://www.anthropic.com/pricing](https://www.anthropic.com/pricing)
- **Google Cloud Vertex AI** : [https://cloud.google.com/vertex-ai/pricing](https://cloud.google.com/vertex-ai/pricing)
- **Azure OpenAI** : [https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
- **AWS Bedrock** : [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)

### Analyses de Co√ªts

- **A16Z AI Cost Analysis**
  - [Reports](https://a16z.com/ai-infrastructure/)
  - Focus : √âconomie de l'infrastructure IA

- **Sequoia Capital AI Insights**
  - [AI's $600B Question](https://www.sequoiacap.com/article/ais-600b-question/)
  - Perspective : Retour sur investissement IA

---

## üîÑ M√©thodologie de Mise √† Jour

### Fr√©quence de R√©vision
- **Donn√©es de performance** : Bi-mensuelle (acc√©l√©ration due √† Grok 4)
- **Prix et disponibilit√©** : Hebdomadaire (march√© tr√®s dynamique)
- **Nouvelles sources** : Continue
- **Validation crois√©e** : Mensuelle
- **Benchmarks √©mergents** : Suivi en temps r√©el (ARC-AGI, HLE)

### Processus de Validation
1. **V√©rification des sources primaires**
2. **Recoupement avec sources secondaires**
3. **Test empirique quand possible**
4. **Peer review des modifications**

### Historique des Versions
- **v1.0.0** (Juillet 2025) : Version initiale avec Grok 3
- **v1.0.1** (10 Juillet 2025) : Mise √† jour Grok 4, nouveaux benchmarks ARC-AGI-2/HLE
- **Futures versions** : Voir [CHANGELOG-FR.md](./CHANGELOG-FR.md)

---

*Derni√®re mise √† jour : 10 Juillet 2025 (Grok 4 int√©gr√©)*  
*Licence : MIT - Voir [LICENSE](../LICENSE)*
