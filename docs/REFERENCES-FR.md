# üìö R√©f√©rences et sources

> Documentation compl√®te des sources utilis√©es pour l'analyse comparative des chatbots IA 2025

---

## üî¨ Sources acad√©miques et de recherche

### Benchmarks et m√©triques de performance

- **MMLU Pro (Massive Multitask Language Understanding Professional)**
  - [Paper original MMLU](https://arxiv.org/abs/2009.03300) - Hendrycks et al., 2020
  - [MMLU Pro Enhanced](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu-pro)
  - Description : version professionnelle du benchmark MMLU avec 12,000 questions sp√©cialis√©es
  - Source donn√©es : Artificial Analysis Database (juillet 2025)

- **LiveCodeBench**
  - [Benchmark officiel](https://livecodebench.github.io/)
  - [Paper de r√©f√©rence](https://arxiv.org/abs/2403.07974) - Jain et al., 2024
  - Description : benchmark de programmation en temps r√©el avec 400+ probl√®mes actualis√©s
  - Usage : √©valuation des capacit√©s de codage en conditions r√©elles

- **Artificial Analysis Intelligence Index**
  - [Site officiel](https://artificialanalysis.ai/)
  - [M√©thodologie](https://artificialanalysis.ai/methodology)
  - Description : m√©trique composite agr√©geant 7 benchmarks diff√©rents
  - Mise √† jour : mensuelle
  - Usage : √©valuation globale de l'intelligence artificielle

- **FLI AI Safety Index**
  - [Rapport complet Summer 2025](https://futureoflife.org/ai-safety-index-2025)
  - [Future of Life Institute](https://futureoflife.org)
  - Description : √©valuation ind√©pendante de la gouvernance et s√©curit√© IA
  - Panel d'experts : 6 chercheurs ind√©pendants reconnus
  - P√©riode d'√©valuation : mars-juillet 2025

### √âtudes sur l'efficacit√© √©nerg√©tique

- **"Energy and Policy Considerations for Deep Learning in NLP"**
  - [Paper complet](https://arxiv.org/abs/1906.02243) - Strubell et al., 2019
  - Impact : premi√®re √©tude majeure sur la consommation √©nerg√©tique des mod√®les NLP

- **"Carbon Emissions and Large Neural Network Training"**
  - [√âtude MIT](https://arxiv.org/abs/2104.10350) - Henderson et al., 2020
  - M√©thodologie : calcul de l'empreinte carbone des mod√®les d'IA

- **"Green AI"**
  - [Article de r√©f√©rence](https://arxiv.org/abs/1907.10597) - Schwartz et al., 2020
  - Vision : d√©veloppement d'IA plus respectueuse de l'environnement

---

## üè¢ Documentation officielle des entreprises

### OpenAI (ChatGPT-4o)

- **Site officiel** : [https://openai.com](https://openai.com)
- **Documentation API** : [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **Research Papers** : [https://openai.com/research](https://openai.com/research)
- **GPT-4 Technical Report** : [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
- **Pricing** : [https://openai.com/pricing](https://openai.com/pricing)
- **Usage Policies** : [https://openai.com/policies/usage-policies](https://openai.com/policies/usage-policies)
- **Preparedness Framework** : [https://cdn.openai.com/preparedness-framework-beta.pdf](https://cdn.openai.com/preparedness-framework-beta.pdf)

### Anthropic (Claude Sonnet 4)

- **Site principal** : [https://anthropic.com](https://anthropic.com)
- **Documentation Claude** : [https://docs.anthropic.com](https://docs.anthropic.com)
- **Constitutional AI Paper** : [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)
- **Claude 4 Model Card** : [https://www.anthropic.com/claude-4-model-card](https://www.anthropic.com/claude-4-model-card)
- **Safety Research** : [https://anthropic.com/safety](https://anthropic.com/safety)
- **Responsible Scaling Policy** : [https://www.anthropic.com/responsible-scaling-policy](https://www.anthropic.com/responsible-scaling-policy)
- **API Pricing** : [https://www.anthropic.com/pricing](https://www.anthropic.com/pricing)

### Google (Gemini 2.5 Pro)

- **Gemini Official** : [https://gemini.google.com](https://gemini.google.com)
- **Google AI** : [https://ai.google](https://ai.google)
- **Gemini Technical Report** : [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805)
- **Google Cloud AI** : [https://cloud.google.com/ai](https://cloud.google.com/ai)
- **Frontier Safety Framework** : [https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/](https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/)
- **Vertex AI Pricing** : [https://cloud.google.com/vertex-ai/pricing](https://cloud.google.com/vertex-ai/pricing)

### Microsoft (Copilot)

- **Microsoft Copilot** : [https://copilot.microsoft.com](https://copilot.microsoft.com)
- **Microsoft 365 Copilot** : [https://www.microsoft.com/en-us/microsoft-365/copilot](https://www.microsoft.com/en-us/microsoft-365/copilot)
- **Documentation API** : [https://learn.microsoft.com/en-us/microsoft-365-copilot/](https://learn.microsoft.com/en-us/microsoft-365-copilot/)
- **Responsible AI Standards** : [https://www.microsoft.com/en-us/ai/responsible-ai](https://www.microsoft.com/en-us/ai/responsible-ai)
- **Pricing** : [https://www.microsoft.com/en-us/microsoft-365/copilot/pricing](https://www.microsoft.com/en-us/microsoft-365/copilot/pricing)
- **Azure AI Services** : [https://azure.microsoft.com/en-us/products/ai-services](https://azure.microsoft.com/en-us/products/ai-services)

### Perplexity AI

- **Site officiel** : [https://perplexity.ai](https://perplexity.ai)
- **Blog technique** : [https://blog.perplexity.ai](https://blog.perplexity.ai)
- **Documentation API** : [https://docs.perplexity.ai](https://docs.perplexity.ai)
- **Research Publications** : [https://perplexity.ai/research](https://perplexity.ai/research)

### Mistral AI

- **Site principal** : [https://mistral.ai](https://mistral.ai)
- **Documentation** : [https://docs.mistral.ai](https://docs.mistral.ai)
- **Mistral 7B Paper** : [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825)
- **Platform** : [https://console.mistral.ai](https://console.mistral.ai)
- **GitHub** : [https://github.com/mistralai](https://github.com/mistralai)
- **Mistral Large 2 Announcement** : [https://mistral.ai/news/mistral-large-2/](https://mistral.ai/news/mistral-large-2/)

### xAI (Grok 4)

- **Site officiel** : [https://x.ai](https://x.ai)
- **Grok on X/Twitter** : [https://twitter.com/grok](https://twitter.com/grok)
- **Technical Blog** : [https://x.ai/blog](https://x.ai/blog)
- **API Documentation** : [https://docs.x.ai/api](https://docs.x.ai/api)
- **Risk Management Framework** : [https://x.ai/safety](https://x.ai/safety)

### DeepSeek

- **Site principal** : [https://deepseek.com](https://deepseek.com)
- **Chat Interface** : [https://chat.deepseek.com](https://chat.deepseek.com)
- **GitHub** : [https://github.com/deepseek-ai](https://github.com/deepseek-ai)
- **DeepSeek-R1 Paper** : [https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)
- **DeepSeek V3 Technical Report** : [https://arxiv.org/abs/2412.19437](https://arxiv.org/abs/2412.19437)

### Alibaba (Qwen 2.5 Max)

- **Tongyi Qianwen** : [https://tongyi.aliyun.com](https://tongyi.aliyun.com)
- **Alibaba Cloud** : [https://www.alibabacloud.com/product/dashscope](https://www.alibabacloud.com/product/dashscope)
- **Qwen GitHub** : [https://github.com/QwenLM](https://github.com/QwenLM)
- **Qwen Technical Report** : [https://arxiv.org/abs/2309.16609](https://arxiv.org/abs/2309.16609)
- **Qwen2.5 Release** : [https://qwenlm.github.io/blog/qwen2.5/](https://qwenlm.github.io/blog/qwen2.5/)

### Moonshot AI (Kimi K2)

- **Site officiel** : [https://www.moonshot.ai](https://www.moonshot.ai)
- **Platform API** : [https://platform.moonshot.ai](https://platform.moonshot.ai)
- **Kimi Chat** : [https://kimi.moonshot.ai](https://kimi.moonshot.ai)
- **GitHub** : [https://github.com/moonshot-ai](https://github.com/moonshot-ai)
- **Technical Documentation** : [https://platform.moonshot.ai/docs](https://platform.moonshot.ai/docs)

---

## üìä Sources de donn√©es et m√©triques

### Base de donn√©es principale : Artificial Analysis

- **Site officiel** : [https://artificialanalysis.ai](https://artificialanalysis.ai)
- **Database Access** : [https://artificialanalysis.ai/data](https://artificialanalysis.ai/data)
- **Methodology** : [https://artificialanalysis.ai/methodology](https://artificialanalysis.ai/methodology)
- **Attribution Requirements** : https://artificialanalysis.ai (attribution requise)
- **Brand Kit** : [https://artificialanalysis.ai/brand-kit](https://artificialanalysis.ai/brand-kit)
- **Fichier source** : modelsdata_20250719.xlsx (223 mod√®les √©valu√©s)

**M√©triques collect√©es :**
- Intelligence Index composite
- MMLU Pro scores
- LiveCodeBench performance
- Vitesse g√©n√©ration (tokens/seconde)
- Prix API actualis√©s
- Temps premi√®re r√©ponse

### Gouvernance : Future of Life Institute

- **FLI AI Safety Index Summer 2025** : [https://futureoflife.org/ai-safety-index-2025](https://futureoflife.org/ai-safety-index-2025)
- **Methodology** : [https://futureoflife.org/ai-safety-index-methodology](https://futureoflife.org/ai-safety-index-methodology)
- **Expert Panel** : Dylan Hadfield-Menell (MIT), Jessica Newman (UC Berkeley), Tegan Maharaj (HEC Montr√©al), Sneha Revanur (Encode), Stuart Russell (UC Berkeley), David Krueger (Universit√© de Montr√©al)
- **Report PDF** : [FLI-AI-Safety-Index-Report-Summer-2025.pdf](https://futureoflife.org/wp-content/uploads/2025/07/FLI-AI-Safety-Index-Report-Summer-2025.pdf)

**Domaines √©valu√©s :**
- Gouvernance & Responsabilit√©
- √âvaluation des risques
- Dommages actuels
- Cadres de s√©curit√©
- S√©curit√© existentielle
- Partage d'information

### Consommation √©nerg√©tique

- **ML CO2 Impact Calculator**
  - [Outil en ligne](https://mlco2.github.io/impact/)
  - [GitHub Repository](https://github.com/mlco2/impact)
  - Usage : calcul de l'empreinte carbone des mod√®les ML

- **CodeCarbon**
  - [Site officiel](https://codecarbon.io/)
  - [GitHub](https://github.com/mlco2/codecarbon)
  - Application : tracking de la consommation √©nerg√©tique

- **Green Algorithms**
  - [Calculator](http://calculator.green-algorithms.org/)
  - [Paper](https://onlinelibrary.wiley.com/doi/10.1002/advs.202100707)
  - Fonction : estimation de l'impact environnemental

### Autres bases de donn√©es de performance

- **Papers With Code**
  - [Leaderboards](https://paperswithcode.com/sota)
  - [MMLU Results](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)
  - R√©f√©rence : comparaisons de performance standardis√©es

- **LMSYS Chatbot Arena**
  - [Plateforme](https://chat.lmsys.org/)
  - [Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
  - [Methodology Paper](https://arxiv.org/abs/2403.04132)
  - Usage : √©valuations humaines en temps r√©el

- **EleutherAI Evaluation Harness**
  - [GitHub](https://github.com/EleutherAI/lm-evaluation-harness)
  - [Documentation](https://github.com/EleutherAI/lm-evaluation-harness/tree/master/docs)
  - R√¥le : framework d'√©valuation standardis√©

---

## üîç Sources d'information industrielle

### Analyses de march√©

- **Gartner AI Reports**
  - [Magic Quadrant for Cloud AI Developer Services](https://www.gartner.com/en/research)
  - [Emerging Technologies Impact Radar](https://www.gartner.com/en/research/methodologies/emerging-technologies-impact-radar)

- **McKinsey Global Institute**
  - [The State of AI in 2025](https://www.mckinsey.com/capabilities/quantumblack/our-insights)
  - [AI and the Future of Work](https://www.mckinsey.com/featured-insights/future-of-work)

- **IDC AI Research**
  - [Worldwide AI Software Platforms Forecast](https://www.idc.com/research/ai)
  - [AI Use Cases](https://www.idc.com/research/artificial-intelligence)

### Publications techniques et actualit√©s IA

- **Nature Machine Intelligence**
  - [Recent AI Publications](https://www.nature.com/natmachintell/)
  - Focus : recherche acad√©mique de pointe

- **Journal of Machine Learning Research (JMLR)**
  - [Open Access Papers](https://www.jmlr.org/)
  - Sp√©cialit√© : algorithmes et th√©orie ML

- **AI Magazine (AAAI)**
  - [Current Issues](https://onlinelibrary.wiley.com/journal/23716621)
  - Contenu : applications et tendances IA

### Sources d'actualit√©s technologiques

- **TechCrunch AI Section**
  - [https://techcrunch.com/category/artificial-intelligence/](https://techcrunch.com/category/artificial-intelligence/)
  - Coverage : actualit√©s et analyses IA

- **The Verge AI Coverage**
  - [https://www.theverge.com/ai-artificial-intelligence](https://www.theverge.com/ai-artificial-intelligence)
  - Focus : impact technologique et soci√©tal

- **MIT Technology Review**
  - [https://www.technologyreview.com/topic/artificial-intelligence/](https://www.technologyreview.com/topic/artificial-intelligence/)
  - Sp√©cialit√© : analyses approfondies et prospective

---

## üåç Sources r√©glementaires et conformit√©

### R√©glementation europ√©enne

- **AI Act de l'UE**
  - [Texte officiel](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206)
  - [Guide d'impl√©mentation](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)
  - [Version fran√ßaise](https://eur-lex.europa.eu/legal-content/FR/TXT/?uri=CELEX:52021PC0206)

- **RGPD**
  - [R√®glement complet](https://eur-lex.europa.eu/legal-content/FR/TXT/?uri=CELEX:32016R0679)
  - [Guide CNIL](https://www.cnil.fr/fr/intelligence-artificielle)

### Standards internationaux

- **ISO/IEC 23053:2022**
  - [Framework for AI Risk Management](https://www.iso.org/standard/74438.html)
  - Application : gestion des risques IA

- **NIST AI Risk Management Framework**
  - [AI RMF 1.0](https://www.nist.gov/itl/ai-risk-management-framework)
  - [Documentation compl√®te](https://doi.org/10.6028/NIST.AI.100-1)

---

## üõ†Ô∏è Outils et m√©thodologies

### Frameworks d'√©valuation

- **OpenCompass**
  - [GitHub](https://github.com/open-compass/opencompass)
  - [Documentation](https://opencompass.org.cn/doc)
  - Usage : √©valuation comparative de LLMs

- **LangChain Evaluators**
  - [Documentation](https://python.langchain.com/docs/guides/productionization/evaluation/)
  - [GitHub](https://github.com/langchain-ai/langchain)

- **MLflow**
  - [Site officiel](https://mlflow.org/)
  - [GitHub](https://github.com/mlflow/mlflow)
  - Fonction : tracking et √©valuation de mod√®les

### Outils de benchmark

- **HELM (Holistic Evaluation of Language Models)**
  - [Stanford HAI](https://crfm.stanford.edu/helm/)
  - [GitHub](https://github.com/stanford-crfm/helm)
  - [Live Results](https://crfm.stanford.edu/helm/latest/)

- **BigBench**
  - [Paper](https://arxiv.org/abs/2206.04615)
  - [GitHub](https://github.com/google/BIG-bench)
  - Sp√©cialit√© : √©valuation √† grande √©chelle

---

## üìà Donn√©es √©conomiques et pricing

### Sources de prix API (juillet 2025)

- **OpenAI Pricing** : [https://openai.com/pricing](https://openai.com/pricing)
- **Anthropic Pricing** : [https://www.anthropic.com/pricing](https://www.anthropic.com/pricing)
- **Google Cloud Vertex AI** : [https://cloud.google.com/vertex-ai/pricing](https://cloud.google.com/vertex-ai/pricing)
- **Microsoft Copilot Pricing** : [https://www.microsoft.com/en-us/microsoft-365/copilot/pricing](https://www.microsoft.com/en-us/microsoft-365/copilot/pricing)
- **Azure OpenAI** : [https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
- **AWS Bedrock** : [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
- **Mistral AI Pricing** : [https://mistral.ai/technology/#pricing](https://mistral.ai/technology/#pricing)

### Analyses de co√ªts

- **A16Z AI Cost Analysis**
  - [Reports](https://a16z.com/ai-infrastructure/)
  - Focus : √©conomie de l'infrastructure IA

- **Sequoia Capital AI Insights**
  - [AI's $600B Question](https://www.sequoiacap.com/article/ais-600b-question/)
  - Perspective : retour sur investissement IA

---

## üìö Recherche et publications connexes

### Papers fondamentaux

- **"Attention Is All You Need"**
  - [Paper](https://arxiv.org/abs/1706.03762) - Vaswani et al., 2017
  - Impact : architecture Transformer

- **"Language Models are Few-Shot Learners"**
  - [Paper](https://arxiv.org/abs/2005.14165) - Brown et al., 2020
  - Description : GPT-3 et apprentissage few-shot

- **"Constitutional AI: Harmlessness from AI Feedback"**
  - [Paper](https://arxiv.org/abs/2212.08073) - Bai et al., 2022
  - Innovation : entra√Ænement IA avec principes constitutionnels

### √âtudes r√©centes sur la gouvernance IA

- **"AI Governance and the Policymaker's Dilemma"**
  - [Stanford HAI](https://hai.stanford.edu/policy)
  - Focus : d√©fis r√©glementaires de l'IA

- **"The Ethics of AI Safety"**
  - [Paper](https://arxiv.org/abs/2404.16793) - Russell et al., 2024
  - Th√®me : consid√©rations √©thiques en s√©curit√© IA

---

## üîÑ M√©thodologie de mise √† jour

### Fr√©quence de r√©vision
- **Donn√©es Artificial Analysis** : mensuelle (synchronisation automatique)
- **FLI AI Safety Index** : bi-annuelle (√©t√©/hiver)
- **Prix et disponibilit√©** : hebdomadaire (march√© tr√®s dynamique)
- **Nouvelles sources** : continue
- **Validation crois√©e** : mensuelle
- **Benchmarks √©mergents** : suivi en temps r√©el

### Processus de validation
1. **V√©rification des sources primaires**
2. **Recoupement avec sources secondaires**
3. **Test empirique quand possible**
4. **Peer review des modifications**
5. **Attribution correcte des donn√©es tierces**

### Historique des versions
- **v1.0.0** (juillet 2025) : version initiale
- **v2.0.0** (juillet 2025) : int√©gration Artificial Analysis + FLI AI Safety Index
- **v2.0.1** (juillet 2025) : ajout Microsoft Copilot et Kimi K2
- **Futures versions** : voir [CHANGELOG-FR.md](./CHANGELOG-FR.md)

---

## üìÑ Licences et attributions

### Donn√©es tierces

- **Artificial Analysis** : attribution requise pour toute utilisation ([https://artificialanalysis.ai](https://artificialanalysis.ai))
- **FLI AI Safety Index** : citation requise (Future of Life Institute, 2025)
- **Papers acad√©miques** : citations selon standards acad√©miques
- **Documentation entreprises** : utilisation √©quitable (fair use)

### Notre travail

- **Analyse et m√©thodologie** : CC BY 4.0
- **Code et scripts** : MIT License
- **Dashboard et visualisations** : CC BY 4.0

---

## ‚ö†Ô∏è Avertissements et limitations

### Limitations des donn√©es

- **Artificial Analysis** : √©chantillon de mod√®les disponibles publiquement
- **FLI Safety Index** : perspective occidentale dominante pour la gouvernance
- **M√©triques √©nerg√©tiques** : estimations avec marge d'erreur ¬±15%
- **Prix API** : fluctuations fr√©quentes, snapshot au moment de l'analyse

### Responsabilit√©s

- **Donn√©es tierces** : nous ne sommes pas responsables de l'exactitude des sources externes
- **√âvolution rapide** : les performances et prix peuvent changer rapidement
- **Usage commercial** : v√©rifier les licences appropri√©es pour usage commercial

---

*Derni√®re mise √† jour : juillet 2025*  
*Sources principales : Artificial Analysis Database, FLI AI Safety Index Summer 2025*  
*Licence : MIT - Voir [LICENSE](../LICENSE)*
